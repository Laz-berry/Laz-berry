# Data Engineer

Hello, I'm a Data Engineer with a passion for handling and transforming data into valuable insights. I specialize in designing and building scalable data infrastructure to support data-driven applications.

## ðŸŽ†Skills

- <img src="https://img.shields.io/badge/Android-3DDC84?style=flat-square&logo=Android&logoColor=white"/> <img src="https://img.shields.io/badge/Python-3776AB?style=flat-square&logo=Python&logoColor=yellow"/> <img src="https://img.shields.io/badge/Jupyter-F37626?style=flat-square&logo=Jupyter&logoColor=yellow"/> <img src="https://img.shields.io/badge/C-A8B9CC?style=flat-square&logo=C&logoColor=blue"/> <img src="https://img.shields.io/badge/C++-00599C?style=flat-square&logo=cplusplus&logoColor=white"/>
- **Data Processing**: Proficient in working with large datasets and implementing ETL (Extract, Transform, Load) processes to cleanse, transform, and aggregate data.
- **Database Technologies**: Experienced in working with various database systems such as SQL, NoSQL, and data warehousing solutions.
- **Data Modeling**: Skilled in creating efficient data models that meet business requirements and enable efficient data retrieval.
- **Big Data Technologies**: Familiar with distributed computing frameworks like Hadoop, Apache Spark, and Apache Flink for processing big data at scale.
- **Data Pipeline Orchestration**: Knowledgeable in workflow management tools like Apache Airflow or Luigi for orchestrating complex data pipelines.
- **Data Visualization**: Proficient in using visualization tools like Tableau or Power BI to create interactive dashboards and reports.
- **Programming**: Strong programming skills in languages such as Python, SQL, and experience with scripting languages like Bash.

## ðŸ“˜Projects

- **Real-Time Data Processing**: Developed a real-time data pipeline using Apache Kafka, Apache Spark Streaming, and Elasticsearch to process and analyze streaming data.
- **Data Warehouse Implementation**: Designed and implemented a cloud-based data warehouse using Amazon Redshift, ensuring high scalability and performance.
- **ETL Automation**: Built an automated ETL pipeline using Python and Apache Airflow to extract data from multiple sources, transform it, and load it into a data warehouse.
- **Data Quality Monitoring**: Developed a data quality monitoring system using SQL queries and data profiling techniques to identify and resolve data quality issues.

## ðŸŽ©Education

- **Bachelor's degree of Faculty of AI Convergence**: Soongsil University, 2017. 3 ~ 2023. 8

## Certifications

- **Certified Data Engineer (CDE)**: Year
- **AWS Certified Big Data - Specialty**: Year

## Contact Me

Feel free to reach out to me to discuss any data engineering opportunities or collaborations.

- Email: [your-email@example.com](mailto:your-email@example.com)
- LinkedIn: [Your Name](https://www.linkedin.com/in/yourname)
- Portfolio: [Your Portfolio](https://your-portfolio-website.com)
